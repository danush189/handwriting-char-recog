{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1400106,"sourceType":"datasetVersion","datasetId":818027},{"sourceId":8981843,"sourceType":"datasetVersion","datasetId":5408762},{"sourceId":8993472,"sourceType":"datasetVersion","datasetId":5417063},{"sourceId":8993742,"sourceType":"datasetVersion","datasetId":5417236},{"sourceId":8993848,"sourceType":"datasetVersion","datasetId":5417302},{"sourceId":8994999,"sourceType":"datasetVersion","datasetId":5417992},{"sourceId":8995009,"sourceType":"datasetVersion","datasetId":5417998},{"sourceId":79614,"sourceType":"modelInstanceVersion","modelInstanceId":66892,"modelId":91901}],"dockerImageVersionId":30260,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/danush121/ml-aat?scriptVersionId=189031895\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Handwriting Recognition using CNN + RNN\n\n\n## Loading Python Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport scipy as sp\nimport random\nimport warnings\nimport string\nimport datetime\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline\n\nimport tensorflow as tf\nfrom keras import backend as K\nfrom keras.models import Model\nfrom keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Bidirectional, LSTM, Dense, Lambda, Activation, BatchNormalization, Dropout\nfrom tensorflow.keras.optimizers import Adam","metadata":{"execution":{"iopub.status.busy":"2024-07-19T13:42:21.435279Z","iopub.execute_input":"2024-07-19T13:42:21.435996Z","iopub.status.idle":"2024-07-19T13:42:21.448868Z","shell.execute_reply.started":"2024-07-19T13:42:21.435942Z","shell.execute_reply":"2024-07-19T13:42:21.447653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading, Viewing Dataset\n\n","metadata":{}},{"cell_type":"code","source":"train_name = pd.read_csv('../input/handwriting-recognition/written_name_train_v2.csv')\ntest_name = pd.read_csv('../input/handwriting-recognition/written_name_test_v2.csv')\nval_name = pd.read_csv('../input/handwriting-recognition/written_name_validation_v2.csv')","metadata":{"execution":{"iopub.status.busy":"2024-07-19T13:42:21.45164Z","iopub.execute_input":"2024-07-19T13:42:21.451984Z","iopub.status.idle":"2024-07-19T13:42:22.052236Z","shell.execute_reply.started":"2024-07-19T13:42:21.451933Z","shell.execute_reply":"2024-07-19T13:42:22.051253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_name.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-19T13:42:22.05359Z","iopub.execute_input":"2024-07-19T13:42:22.053999Z","iopub.status.idle":"2024-07-19T13:42:22.07598Z","shell.execute_reply.started":"2024-07-19T13:42:22.053939Z","shell.execute_reply":"2024-07-19T13:42:22.074915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_name.describe()","metadata":{"execution":{"iopub.status.busy":"2024-07-19T13:42:22.077235Z","iopub.execute_input":"2024-07-19T13:42:22.07752Z","iopub.status.idle":"2024-07-19T13:42:22.562688Z","shell.execute_reply.started":"2024-07-19T13:42:22.077494Z","shell.execute_reply":"2024-07-19T13:42:22.561391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_name.describe()","metadata":{"execution":{"iopub.status.busy":"2024-07-19T13:42:22.566018Z","iopub.execute_input":"2024-07-19T13:42:22.566785Z","iopub.status.idle":"2024-07-19T13:42:22.627487Z","shell.execute_reply.started":"2024-07-19T13:42:22.566737Z","shell.execute_reply":"2024-07-19T13:42:22.626514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_name.info()","metadata":{"execution":{"iopub.status.busy":"2024-07-19T13:42:22.628842Z","iopub.execute_input":"2024-07-19T13:42:22.629312Z","iopub.status.idle":"2024-07-19T13:42:22.716684Z","shell.execute_reply.started":"2024-07-19T13:42:22.629258Z","shell.execute_reply":"2024-07-19T13:42:22.715623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_name.info()","metadata":{"execution":{"iopub.status.busy":"2024-07-19T13:42:22.718167Z","iopub.execute_input":"2024-07-19T13:42:22.718543Z","iopub.status.idle":"2024-07-19T13:42:22.745761Z","shell.execute_reply.started":"2024-07-19T13:42:22.718509Z","shell.execute_reply":"2024-07-19T13:42:22.744472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_name.shape","metadata":{"execution":{"iopub.status.busy":"2024-07-19T13:42:22.747323Z","iopub.execute_input":"2024-07-19T13:42:22.747775Z","iopub.status.idle":"2024-07-19T13:42:22.757899Z","shell.execute_reply.started":"2024-07-19T13:42:22.747731Z","shell.execute_reply":"2024-07-19T13:42:22.756723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_name.shape","metadata":{"execution":{"iopub.status.busy":"2024-07-19T13:42:22.759134Z","iopub.execute_input":"2024-07-19T13:42:22.759454Z","iopub.status.idle":"2024-07-19T13:42:22.7682Z","shell.execute_reply.started":"2024-07-19T13:42:22.759425Z","shell.execute_reply":"2024-07-19T13:42:22.766984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_name.shape","metadata":{"execution":{"iopub.status.busy":"2024-07-19T13:42:22.769877Z","iopub.execute_input":"2024-07-19T13:42:22.77037Z","iopub.status.idle":"2024-07-19T13:42:22.781625Z","shell.execute_reply.started":"2024-07-19T13:42:22.770328Z","shell.execute_reply":"2024-07-19T13:42:22.780596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_name.dtypes","metadata":{"execution":{"iopub.status.busy":"2024-07-19T13:42:22.783409Z","iopub.execute_input":"2024-07-19T13:42:22.783868Z","iopub.status.idle":"2024-07-19T13:42:22.793504Z","shell.execute_reply.started":"2024-07-19T13:42:22.783823Z","shell.execute_reply":"2024-07-19T13:42:22.792555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_name.columns","metadata":{"execution":{"iopub.status.busy":"2024-07-19T13:42:22.794632Z","iopub.execute_input":"2024-07-19T13:42:22.794936Z","iopub.status.idle":"2024-07-19T13:42:22.804187Z","shell.execute_reply.started":"2024-07-19T13:42:22.794889Z","shell.execute_reply":"2024-07-19T13:42:22.80319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\n\nfor i in range(6):\n    ax = plt.subplot(2, 3, i+1)\n    img_dir = '../input/handwriting-recognition/train_v2/train/'+train_name.loc[i, 'FILENAME']\n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    plt.imshow(image, cmap = 'gray')\n    plt.title(train_name.loc[i, 'IDENTITY'], fontsize=12)\n    plt.axis('off')\n    \nplt.subplots_adjust(wspace=0.2, hspace=-0.8)","metadata":{"execution":{"iopub.status.busy":"2024-07-19T13:42:22.807954Z","iopub.execute_input":"2024-07-19T13:42:22.808442Z","iopub.status.idle":"2024-07-19T13:42:23.338449Z","shell.execute_reply.started":"2024-07-19T13:42:22.808398Z","shell.execute_reply":"2024-07-19T13:42:23.337442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Cleaning\n","metadata":{}},{"cell_type":"code","source":"print(\"Number of NaNs in the train dataset is: \", train_name['IDENTITY'].isnull().sum())\nprint(\"Number of NaNs in the validation dataset is: \", val_name['IDENTITY'].isnull().sum())\nprint(\"Number of NaNs in the test dataset is: \", test_name['IDENTITY'].isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2024-07-19T13:42:23.343325Z","iopub.execute_input":"2024-07-19T13:42:23.343638Z","iopub.status.idle":"2024-07-19T13:42:23.39978Z","shell.execute_reply.started":"2024-07-19T13:42:23.34361Z","shell.execute_reply":"2024-07-19T13:42:23.398743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_name.dropna(axis=0, inplace=True)\nval_name.dropna(axis=0, inplace=True)\ntest_name.dropna(axis=0, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-19T13:42:23.40133Z","iopub.execute_input":"2024-07-19T13:42:23.401778Z","iopub.status.idle":"2024-07-19T13:42:23.52522Z","shell.execute_reply.started":"2024-07-19T13:42:23.401738Z","shell.execute_reply":"2024-07-19T13:42:23.52424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unreadable = train_name[train_name['IDENTITY'] == 'UNREADABLE']\nunreadable.reset_index(inplace = True, drop = True)\n\nplt.figure(figsize=(15,10))\n\nfor i in range(6):\n    ax = plt.subplot(2, 3, i+1)\n    img_dir = '../input/handwriting-recognition/train_v2/train/'+unreadable.loc[i, 'FILENAME']\n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    plt.imshow(image, cmap = 'gray')\n    plt.title(unreadable.loc[i, 'IDENTITY'], fontsize=12)\n    plt.axis('off')\n    \nplt.subplots_adjust(wspace=0.2, hspace=-0.8)","metadata":{"execution":{"iopub.status.busy":"2024-07-19T13:42:23.526455Z","iopub.execute_input":"2024-07-19T13:42:23.526733Z","iopub.status.idle":"2024-07-19T13:42:24.052757Z","shell.execute_reply.started":"2024-07-19T13:42:23.526708Z","shell.execute_reply":"2024-07-19T13:42:24.051712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_name = train_name[train_name['IDENTITY'] != 'UNREADABLE']\nval_name = val_name[val_name['IDENTITY'] != 'UNREADABLE']\ntest_name = test_name[test_name['IDENTITY'] != 'UNREADABLE']","metadata":{"execution":{"iopub.status.busy":"2024-07-19T13:42:24.053948Z","iopub.execute_input":"2024-07-19T13:42:24.054252Z","iopub.status.idle":"2024-07-19T13:42:24.151268Z","shell.execute_reply.started":"2024-07-19T13:42:24.054224Z","shell.execute_reply":"2024-07-19T13:42:24.150306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_name['IDENTITY'] = train_name['IDENTITY'].str.upper()\nval_name['IDENTITY'] = val_name['IDENTITY'].str.upper()\ntest_name['IDENTITY'] = test_name['IDENTITY'].str.upper()","metadata":{"execution":{"iopub.status.busy":"2024-07-19T13:42:24.152636Z","iopub.execute_input":"2024-07-19T13:42:24.153062Z","iopub.status.idle":"2024-07-19T13:42:24.410276Z","shell.execute_reply.started":"2024-07-19T13:42:24.153019Z","shell.execute_reply":"2024-07-19T13:42:24.409344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_name.reset_index(inplace = True, drop = True)\nval_name.reset_index(inplace = True, drop = True)\ntest_name.reset_index(inplace = True, drop = True)","metadata":{"execution":{"iopub.status.busy":"2024-07-19T13:42:24.411439Z","iopub.execute_input":"2024-07-19T13:42:24.411751Z","iopub.status.idle":"2024-07-19T13:42:24.417741Z","shell.execute_reply.started":"2024-07-19T13:42:24.411723Z","shell.execute_reply":"2024-07-19T13:42:24.416663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Image Preprocessing\n","metadata":{}},{"cell_type":"code","source":"def image_processing(img):\n    (h, w) = img.shape\n    \n    final_img = np.ones([64, 256])*255 # blank white image\n    \n    # crop if image dimension exceeds the said criteria\n    if w > 256:\n        img = img[:, :256]\n    if h > 64:\n        img = img[:64, :]\n        \n    final_img[:h, :w] = img\n    return cv2.rotate(final_img, cv2.ROTATE_90_CLOCKWISE)","metadata":{"execution":{"iopub.status.busy":"2024-07-19T13:42:24.419153Z","iopub.execute_input":"2024-07-19T13:42:24.41955Z","iopub.status.idle":"2024-07-19T13:42:24.427951Z","shell.execute_reply.started":"2024-07-19T13:42:24.419511Z","shell.execute_reply":"2024-07-19T13:42:24.426898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"train_size = 30000\nval_size = 3000\ntest_size = 3000\ntrain_x = []\nval_x = []\ntest_x = []\n\nfor i in range(train_size):\n    img_dir = '../input/handwriting-recognition/train_v2/train/' + train_name.loc[i, 'FILENAME']\n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    image = image_processing(image)\n    image = image/255.\n    train_x.append(image)\n    \nfor i in range(val_size):\n    img_dir = '../input/handwriting-recognition/validation_v2/validation/' + val_name.loc[i, 'FILENAME']\n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    image = image_processing(image)\n    image = image/255.\n    val_x.append(image)\n    \nfor i in range(test_size):\n    img_dir = '../input/handwriting-recognition/test_v2/test/' + test_name.loc[i, 'FILENAME']\n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    image = image_processing(image)\n    image = image/255.\n    test_x.append(image)\n    \ntrain_x = np.array(train_x).reshape(-1, 256, 64, 1)\nval_x = np.array(val_x).reshape(-1, 256, 64, 1)\ntest_x = np.array(test_x).reshape(-1, 256, 64, 1)","metadata":{"execution":{"iopub.status.busy":"2024-07-19T13:42:24.429263Z","iopub.execute_input":"2024-07-19T13:42:24.429557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Character processing\n\n","metadata":{}},{"cell_type":"code","source":"alphabets = u\"ABCDEFGHIJKLMNOPQRSTUVWXYZ-' \"\nmax_str_len = 24 \nnum_characters = len(alphabets) + 1 \nnum_of_timestamps = 64 \n\ndef name_to_num(name):\n    name_num = []\n    for ch in name:\n        name_num.append(alphabets.find(ch))\n    return np.array(name_num)\n\ndef num_to_name(num):\n    name = \"\"\n    for ch in num:\n        if ch == -1: # CTC blank\n            break\n        else:\n            name += alphabets[ch]\n    return name","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_y = np.ones([train_size, max_str_len]) * -1\ntrain_name_len = np.zeros([train_size, 1])\ntrain_input_len = np.ones([train_size, 1]) * (num_of_timestamps-2)\ntrain_output = np.zeros([train_size])\n\nfor i in range(train_size):\n    train_name_len[i] = len(train_name.loc[i, 'IDENTITY'])\n    train_y[i, 0:len(train_name.loc[i, 'IDENTITY'])] = name_to_num(train_name.loc[i, 'IDENTITY'])\n\nval_y = np.ones([val_size, max_str_len]) * -1\nval_name_len = np.zeros([val_size, 1])\nval_input_len = np.ones([val_size, 1]) * (num_of_timestamps-2)\nval_output = np.zeros([val_size])\n\nfor i in range(val_size):\n    val_name_len[i] = len(val_name.loc[i, 'IDENTITY'])\n    val_y[i, 0:len(val_name.loc[i, 'IDENTITY'])] = name_to_num(val_name.loc[i, 'IDENTITY'])\n\ntest_y = np.ones([test_size, max_str_len]) * -1\ntest_name_len = np.zeros([test_size, 1])\ntest_input_len = np.ones([test_size, 1]) * (num_of_timestamps-2)\ntest_output = np.zeros([test_size])\n\nfor i in range(test_size):\n    test_name_len[i] = len(test_name.loc[i, 'IDENTITY'])\n    test_y[i, 0:len(test_name.loc[i, 'IDENTITY'])] = name_to_num(test_name.loc[i, 'IDENTITY'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Building a hybrid CNN + RNN model\n\nCNN(3 layers)\nRNN(2 Layers)","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, Dropout, Reshape, Dense, Bidirectional, LSTM, Lambda\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nimport tensorflow.keras.backend as K\n\ndef ctc_lambda_func(args):\n    y_pred, names, input_length, name_length = args\n    y_pred = y_pred[:, 2:, :]\n    return K.ctc_batch_cost(names, y_pred, input_length, name_length)\n\ninput_data = Input(shape=(256, 64, 1), name='input')\n\n# CNN\ninner = Conv2D(32, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(input_data)\ninner = BatchNormalization()(inner)\ninner = Activation('relu')(inner)\ninner = MaxPooling2D(pool_size=(2,2), name='max1')(inner)\n\ninner = Conv2D(64, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(inner)\ninner = BatchNormalization()(inner)\ninner = Activation('relu')(inner)\ninner = MaxPooling2D(pool_size=(2,2), name='max2')(inner)\ninner = Dropout(0.3)(inner)\n\ninner = Conv2D(128, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(inner)\ninner = BatchNormalization()(inner)\ninner = Activation('relu')(inner)\ninner = MaxPooling2D(pool_size=(1,2), name='max3')(inner)\ninner = Dropout(0.3)(inner)\n\n# CNN to RNN\ninner = Reshape(target_shape=((64, 1024)), name='reshape')(inner)\ninner = Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(inner)\n\n# RNN\ninner = Bidirectional(LSTM(256, return_sequences=True), name='lstm1')(inner)\ninner = Bidirectional(LSTM(256, return_sequences=True), name='lstm2')(inner)\n\n# Output\ninner = Dense(num_characters, kernel_initializer='he_normal', name='dense2')(inner)\ny_pred = Activation('softmax', name='softmax')(inner)\n\nmodel = Model(inputs=input_data, outputs=y_pred)\n\n\nnames = Input(name='gtruth_names', shape=[max_str_len], dtype='float32')\ninput_length = Input(name='input_length', shape=[1], dtype='int64')\nname_length = Input(name='name_length', shape=[1], dtype='int64')\n\n\nctc_loss = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, names, input_length, name_length])\nmodel_final = Model(inputs=[input_data, names, input_length, name_length], outputs=ctc_loss)\nmodel_final.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=Adam(learning_rate=0.0001))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training the model\n\n","metadata":{}},{"cell_type":"code","source":"model_final.fit(x = [train_x, train_y, train_input_len, train_name_len], y=train_output, validation_data = ([val_x, val_y, val_input_len, val_name_len], val_output), epochs=60, batch_size=128)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## validation \n\n","metadata":{}},{"cell_type":"code","source":"preds = model.predict(val_x)\ndecoded = K.get_value(K.ctc_decode(preds, input_length=np.ones(preds.shape[0])*preds.shape[1], greedy=True)[0][0])\n\nprediction = []\nfor i in range(val_size):\n    prediction.append(num_to_name(decoded[i]))\n    \ny_true = val_name.loc[0:val_size, 'IDENTITY']\ncorrect_char = 0\ntotal_char = 0\ncorrect = 0\n\nfor i in range(val_size):\n    pr = prediction[i]\n    tr = y_true[i]\n    total_char += len(tr)\n    \n    for j in range(min(len(tr), len(pr))):\n        if tr[j] == pr[j]:\n            correct_char += 1\n            \n    if pr == tr:\n        correct += 1\n        \nprint('Correct characters predicted: %.2f%%' %(correct_char*100/total_char))\nprint('Correct words predicted: %.2f%%' %(correct*100/val_size))","metadata":{"execution":{"iopub.status.busy":"2024-07-19T19:39:59.190247Z","iopub.execute_input":"2024-07-19T19:39:59.191021Z","iopub.status.idle":"2024-07-19T19:40:02.860838Z","shell.execute_reply.started":"2024-07-19T19:39:59.190979Z","shell.execute_reply":"2024-07-19T19:40:02.859598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## test\n\n","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Model, load_model\nmod=load_model(\"/kaggle/input/model2/keras/default/1/modelh.h5\")\n\nplt.figure(figsize=(15,10))\n\nfor i in range(6):\n    ax = plt.subplot(2, 3, i+1)\n    img_dir = '../input/handwriting-recognition/test_v2/test/'+test_name.loc[i, 'FILENAME']\n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    plt.imshow(image, cmap = 'gray')\n    \n    image = image_processing(image)\n    image = image/255.\n    pred = mod.predict(image.reshape(1, 256, 64, 1))\n    decoded = K.get_value(K.ctc_decode(pred, input_length = np.ones(pred.shape[0])*pred.shape[1], greedy=True)[0][0])\n    plt.title(num_to_name(decoded[0]), fontsize=12)\n    plt.axis('off')\n    \nplt.subplots_adjust(wspace=0.2, hspace=-0.8)","metadata":{"execution":{"iopub.status.busy":"2024-07-19T20:54:54.505201Z","iopub.execute_input":"2024-07-19T20:54:54.505668Z","iopub.status.idle":"2024-07-19T20:54:58.39646Z","shell.execute_reply.started":"2024-07-19T20:54:54.505631Z","shell.execute_reply":"2024-07-19T20:54:58.395294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predictions","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras import backend as K\n\n# Load the pre-trained model\nmod = load_model(\"/kaggle/input/model2/keras/default/1/modelh.h5\")\n\n# Preprocessing function\ndef image_processing(img):\n    (h, w) = img.shape\n    \n    final_img = np.ones([64, 256]) * 255  # blank white image\n    \n    # Crop if image dimensions exceed the criteria\n    if w > 256:\n        img = img[:, :256]\n    if h > 64:\n        img = img[:64, :]\n        \n    final_img[:h, :w] = img\n    return cv2.rotate(final_img, cv2.ROTATE_90_CLOCKWISE)\n\n# Function to convert prediction to readable text\ndef num_to_name(num):\n    alphabets = u\"ABCDEFGHIJKLMNOPQRSTUVWXYZ-' \"\n    name = \"\"\n    for ch in num:\n        if ch == -1:  # CTC blank\n            break\n        else:\n            name += alphabets[ch]\n    return name\n\n# Path to the custom directory containing the images\ncustom_image_dir = '../input/handwriting-recognition/test_v2/test/'\n\n# List all filenames in the custom directory\nfilenames = os.listdir(custom_image_dir)\n\n# Create a figure for plotting\nplt.figure(figsize=(15, 10))\n\n# Iterate over the filenames and process each image\nfor i, filename in enumerate(filenames):\n    if i >= 6:  # Display only the first 6 images\n        break\n\n    ax = plt.subplot(2, 3, i + 1)\n    img_path = os.path.join(custom_image_dir, filename)\n    image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n    \n    plt.imshow(image, cmap='gray')\n    \n    image = image_processing(image)\n    image = image / 255.0\n    pred = mod.predict(image.reshape(1, 256, 64, 1))\n    decoded = K.get_value(K.ctc_decode(pred, input_length=np.ones(pred.shape[0]) * pred.shape[1], greedy=True)[0][0])\n    plt.title(num_to_name(decoded[0]), fontsize=12)\n    plt.axis('off')\n\n# Adjust the layout\nplt.subplots_adjust(wspace=0.2, hspace=-0.8)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:01:10.801419Z","iopub.execute_input":"2024-07-20T07:01:10.802023Z","iopub.status.idle":"2024-07-20T07:01:33.639778Z","shell.execute_reply.started":"2024-07-20T07:01:10.801941Z","shell.execute_reply":"2024-07-20T07:01:33.638203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras import backend as K\n\n# Load the pre-trained model\nmod = load_model(\"/kaggle/input/model2/keras/default/1/modelh.h5\")\n\n# Preprocessing function\ndef image_processing(img):\n    (h, w) = img.shape\n    \n    final_img = np.ones([64, 256]) * 255  # blank white image\n    \n    # Crop if image dimensions exceed the criteria\n    if w > 256:\n        img = img[:, :256]\n    if h > 64:\n        img = img[:64, :]\n        \n    final_img[:h, :w] = img\n    return cv2.rotate(final_img, cv2.ROTATE_90_CLOCKWISE)\n\n# Function to convert prediction to readable text\ndef num_to_name(num):\n    alphabets = u\"ABCDEFGHIJKLMNOPQRSTUVWXYZ-' \"\n    name = \"\"\n    for ch in num:\n        if ch == -1:  # CTC blank\n            break\n        else:\n            name += alphabets[ch]\n    return name\n\n# Path to the custom directory containing the images\ncustom_image_dir = '/kaggle/input/trial6/des2'\n\n# List all filenames in the custom directory\nfilenames = os.listdir(custom_image_dir)\n\n# Create a figure for plotting\nplt.figure(figsize=(15, 10))\n\n# Iterate over the filenames and process each image\nfor i, filename in enumerate(filenames):\n    if i >= 6:  # Display only the first 6 images\n        break\n\n    ax = plt.subplot(2, 3, i + 1)\n    img_path = os.path.join(custom_image_dir, filename)\n    image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n    \n    plt.imshow(image, cmap='gray')\n    \n    image = image_processing(image)\n    image = image / 255.0\n    pred = mod.predict(image.reshape(1, 256, 64, 1))\n    decoded = K.get_value(K.ctc_decode(pred, input_length=np.ones(pred.shape[0]) * pred.shape[1], greedy=True)[0][0])\n    plt.title(num_to_name(decoded[0]), fontsize=12)\n    plt.axis('off')\n\n# Adjust the layout\nplt.subplots_adjust(wspace=0.2, hspace=-0.8)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:01:38.215134Z","iopub.execute_input":"2024-07-20T07:01:38.216169Z","iopub.status.idle":"2024-07-20T07:01:41.530621Z","shell.execute_reply.started":"2024-07-20T07:01:38.216116Z","shell.execute_reply":"2024-07-20T07:01:41.529343Z"},"trusted":true},"execution_count":null,"outputs":[]}]}